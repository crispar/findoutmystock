{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8\n",
    "import bs4\n",
    "from urllib.request import urlopen\n",
    "import urllib.request as request\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import collections\n",
    "from time import sleep\n",
    "import ssl\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_info(stock_cd):\n",
    "    url_float = 'https://companyinfo.stock.naver.com/company/c1010001.aspx?cmp_cd=' + str(stock_cd)\n",
    "    #print(url_float)\n",
    "    \n",
    "    #if '030200' == str(stock_cd) or '005930' == str(stock_cd):\n",
    "    #    sleep(7)\n",
    "    #    print(url_float)\n",
    "    \n",
    "    #proxy_support = request.ProxyHandler({\"http\": \"http://168.219.61.252:8080/\", \"https\": \"http://168.219.61.252:8080/\"})\n",
    "    #opener = request.build_opener(proxy_support)\n",
    "\n",
    "    source = urlopen(url_float, context = ssl._create_unverified_context()).read()\n",
    "    soup = bs4.BeautifulSoup(source, 'html.parser')\n",
    "    \n",
    "    #if '030200' == str(stock_cd) or '005930' == str(stock_cd):\n",
    "    #    print(source)\n",
    "    #    print(soup)\n",
    "    #    print(soup.find(id='cTB11'))\n",
    "    try:\n",
    "        tmp = soup.find(id='cTB11').find_all('tr')[6].td.text\n",
    "        tmp = tmp.replace('\\r','')\n",
    "        tmp = tmp.replace('\\n','')\n",
    "        tmp = tmp.replace('\\t','')\n",
    "    except IndexError:\n",
    "        print(url_float)\n",
    "    \n",
    "    tmp = re.split('/',tmp)\n",
    "\n",
    "    outstanding = tmp[0].replace(',','')\n",
    "    outstanding = outstanding.replace('주','')\n",
    "    outstanding = outstanding.replace(' ','')\n",
    "    outstanding = int(outstanding)\n",
    "\n",
    "    floating = tmp[1].replace(' ','')\n",
    "    floating = floating.replace('%','')\n",
    "    floating = float(floating)\n",
    "    \n",
    "    name = soup.find(id='pArea').find('div').find('div').find('tr').find('td').find('span').text\n",
    "    \n",
    "    k50_outstanding[stock_cd] = outstanding\n",
    "    k50_floating[stock_cd] = floating\n",
    "    k50_name[stock_cd] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_rank_stocks(num, top_ranks, page_n=1, last_page=0):\n",
    "    url_float = 'https://finance.naver.com/sise/sise_market_sum.nhn?&page=' + str(page_n)\n",
    "\n",
    "    #proxy_support = request.ProxyHandler({\"http\": \"http://168.219.61.252:8080/\", \"https\": \"http://168.219.61.252:8080/\"})\n",
    "    #opener = request.build_opener(proxy_support)\n",
    "\n",
    "    source = urlopen(url_float, context = ssl._create_unverified_context()).read().decode('euc-kr','replace').encode('utf-8','replace')\n",
    "    soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    tmp = soup.find_all('a', href=True)\n",
    "\n",
    "    for stock_name in tmp:\n",
    "        if '/item/main.nhn?code' in stock_name['href']:\n",
    "            #top_ranks.append(stock_name.text:(re.split('=',stock_name['href']))[1])\n",
    "            prefix_matcher = list()\n",
    "            if 'HANARO' in stock_name.text or 'KINDEX' in stock_name.text or 'ARIRANG' in stock_name.text or 'KODEX' in stock_name.text or 'TIGER' in stock_name.text or 'KBSTAR' in stock_name.text or 'TRUE 코스피' in stock_name.text:\n",
    "                continue\n",
    "            \n",
    "            if '우' in stock_name.text:\n",
    "                #print(\"dddddddd\",stock_name.text)                \n",
    "                if '대우' in stock_name.text:\n",
    "                    idx_num = stock_name.text.index('우')\n",
    "                    prefix_matcher.append(stock_name.text[idx_num+1:])\n",
    "                    if '우' in prefix_matcher[0]:\n",
    "                        #print(\"ccccccc\",prefix_matcher[0])\n",
    "                        prefix_matcher[0] = stock_name.text[:idx_num+1]\n",
    "                    else:\n",
    "                        prefix_matcher[0] = stock_name.text                     \n",
    "                    #print(\"bbbbbbbb\",prefix_matcher[0])\n",
    "                else:\n",
    "                    #print(stock_name.text)\n",
    "                    prefix_matcher = re.split('[0-9]*우',stock_name.text)\n",
    "                    #print(prefix_matcher[0], prefix_matcher[0] in top_ranks)\n",
    "                if prefix_matcher[0] in top_ranks:\n",
    "                    #print(\"aaaaaaaa\",stock_name.text)\n",
    "                    continue\n",
    "            #print(stock_name['href'], stock_name.text)\n",
    "            top_ranks[stock_name.text] = (re.split('=',stock_name['href']))[1]\n",
    "\n",
    "        if len(top_ranks) >= num:\n",
    "            return top_ranks\n",
    "\n",
    "    if last_page == 0:\n",
    "        last_page = soup.find('td', class_='pgRR').find('a')['href']\n",
    "        #마지막 주소 추출\n",
    "        last_page = last_page.split('&')[-1]\n",
    "        last_page = int(last_page.split('=')[-1])            \n",
    "\n",
    "    if page_n < last_page:\n",
    "        page_n = page_n + 1\n",
    "        \n",
    "        top_rank_stocks(num, top_ranks, page_n, last_page)\n",
    "    \n",
    "    return top_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(d):\n",
    "    d = str(d).replace('-','.')\n",
    "    yyyy = int(d.split('.')[0])\n",
    "    mm = int(d.split('.')[1])\n",
    "    dd = int(d.split('.')[2])\n",
    "    \n",
    "    this_date = dt.date(yyyy,mm,dd)\n",
    "    return this_date\n",
    "\n",
    "def historical_index_naver_domestic(index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "    if start_date:\n",
    "        start_date = date_time(start_date)\n",
    "    else:\n",
    "        start_date = dt.date.today()\n",
    "        \n",
    "    if end_date:\n",
    "        end_date = date_time(end_date)\n",
    "    else:\n",
    "        end_date = dt.date.today()    \n",
    "    \n",
    "    if index_cd.isdigit() == True:\n",
    "        naver_index = 'https://finance.naver.com/item/sise_day.nhn?code='+index_cd+'&page='+str(page_n)\n",
    "    else:\n",
    "        naver_index = 'https://finance.naver.com/sise/sise_index_day.nhn?code='+index_cd+'&page='+str(page_n)\n",
    "\n",
    "    #proxy_support = request.ProxyHandler({\"http\": \"http://168.219.61.252:8080/\", \"https\": \"http://168.219.61.252:8080/\"})\n",
    "    #opener = request.build_opener(proxy_support)\n",
    "\n",
    "    source = urlopen(naver_index,context = ssl._create_unverified_context()).read()             #지정한 페이지 읽기\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')       #BeautifulSoup으로 태그별 코드 분류\n",
    "    \n",
    "\n",
    "    if index_cd.isdigit() == True:\n",
    "        dates = source.find_all('span', class_='tah p10 gray03')\n",
    "        prices = source.find_all('td', class_='num')\n",
    "        prices_temp = prices.copy()\n",
    "        prices_temp.clear()\n",
    "        #print(type(source),type(prices))\n",
    "        for words in prices:\n",
    "            prices_temp += words.find_all('span')\n",
    "        prices = prices_temp\n",
    "    else:\n",
    "        dates = source.find_all('td', class_='date')\n",
    "        prices = source.find_all('td', class_='number_1')\n",
    "    \n",
    "    for n in range(len(dates)):\n",
    "        if dates[n].text.split('.')[0].isdigit():\n",
    "            this_date = dates[n].text\n",
    "            this_date = date_time(this_date)\n",
    "            \n",
    "            \n",
    "            if this_date <= end_date and this_date >= start_date:\n",
    "                temp_prices = dict()               \n",
    "                if index_cd.isdigit() == True:\n",
    "                    temp_prices['종가'] = prices[n*6].text #종가\n",
    "                    temp_prices['종가'] = float(temp_prices['종가'].replace(',',''))\n",
    "                    temp_prices['시가'] = prices[n*6 + 2].text #시가\n",
    "                    temp_prices['시가'] = float(temp_prices['시가'].replace(',',''))\n",
    "                    if temp_prices['시가'] == 0:\n",
    "                        temp_prices['시가'] = temp_prices['종가']\n",
    "                    temp_prices['고가'] = prices[n*6 + 3].text #고가\n",
    "                    temp_prices['고가'] = float(temp_prices['고가'].replace(',',''))\n",
    "                    if temp_prices['고가'] == 0:\n",
    "                        temp_prices['고가'] = temp_prices['종가']\n",
    "                    temp_prices['저가'] = prices[n*6 + 4].text #고가\n",
    "                    temp_prices['저가'] = float(temp_prices['저가'].replace(',',''))\n",
    "                    if temp_prices['저가'] == 0:\n",
    "                        temp_prices['저가'] = temp_prices['종가']\n",
    "                    this_close = temp_prices\n",
    "                    #print(this_close)\n",
    "                else:\n",
    "                    this_close = prices[n*4].text\n",
    "                    this_close = this_close.replace(',','')\n",
    "                    this_close = float(this_close)\n",
    "\n",
    "                historical_prices[this_date] = this_close\n",
    "                \n",
    "            elif this_date < start_date:\n",
    "                return historical_prices\n",
    "    \n",
    "    if last_page == 0:\n",
    "        #print(naver_index)\n",
    "        #print(source)\n",
    "        #print(source.find('td', class_='pgRR'))\n",
    "        if (source.find('td', class_='pgRR') != None):\n",
    "            last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "            #마지막 주소 추출\n",
    "            last_page = last_page.split('&')[-1]\n",
    "            last_page = int(last_page.split('=')[-1])\n",
    "        \n",
    "    if page_n < last_page:\n",
    "        page_n = page_n + 1\n",
    "        historical_index_naver_domestic(index_cd, start_date, end_date, page_n, last_page)\n",
    "    \n",
    "    return historical_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranks = collections.OrderedDict()\n",
    "k50_outstanding = dict()\n",
    "k50_floating = dict()\n",
    "k50_name = dict()\n",
    "\n",
    "top_ranks = top_rank_stocks(10, top_ranks)\n",
    "#print(top_ranks.values())\n",
    "k50_component = top_ranks.values()\n",
    "for stock_cd in k50_component:\n",
    "    #print(stock_cd)\n",
    "    stock_info(stock_cd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k50_historical_prices = dict()\n",
    "date1 = dt.date.today()\n",
    "date2 = dt.timedelta(days=366)\n",
    "start_day = date1 - date2\n",
    "for stock_cd in k50_component:\n",
    "    \n",
    "    historical_prices = dict()\n",
    "    start_date = str(start_day.year) + '-' + str(start_day.month) + '-' + str(start_day.day)\n",
    "    end_date = str(date1.year) + '-' + str(date1.month) + '-' + str(date1.day)\n",
    "    historical_index_naver_domestic(stock_cd, start_date, end_date)\n",
    "    \n",
    "    if top_ranks['삼성전자'] == stock_cd:\n",
    "        tmp_historical_prices = dict()\n",
    "        divideDate = dt.date(2018,5,4)\n",
    "        tmp_historical_prices = dict()\n",
    "        for key, value in historical_prices.items():\n",
    "            if type(value) is dict:\n",
    "                tmp_prices = dict()\n",
    "                for inner_key, inner_value in value.items():\n",
    "                    if date_time(key) < divideDate:\n",
    "                        tmp_prices[inner_key] = float(inner_value)/50\n",
    "                    else:\n",
    "                        tmp_prices[inner_key] = float(inner_value)\n",
    "                tmp_historical_prices[key] = tmp_prices\n",
    "            else:\n",
    "                if date_time(key) < divideDate:\n",
    "                    tmp_historical_prices[key] = float(value)/50\n",
    "                else:\n",
    "                    tmp_historical_prices[key] = float(value)\n",
    "\n",
    "        k50_historical_prices[stock_cd] = tmp_historical_prices\n",
    "    else:\n",
    "        k50_historical_prices[stock_cd] = historical_prices\n",
    "    \n",
    "k50_historical_prices = pd.DataFrame(k50_historical_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k50_historical_prices = k50_historical_prices.fillna(method='ffill')\n",
    "if k50_historical_prices.isnull().values.any():\n",
    "    k50_historical_prices = k50_historical_prices.fillna(method='bfill')\n",
    "#k50_historical_prices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k50_min = dict()\n",
    "K50_min_date = dict()\n",
    "K50_gap = dict()\n",
    "today = dt.date.today()\n",
    "for key, values in k50_historical_prices.items():\n",
    "    #print(key, values[dt.date(2018,4,30)])\n",
    "    key_name = str()\n",
    "    search_list = values[:-1]\n",
    "    key_min_date = min(search_list.keys(), key=(lambda k: search_list[k]['저가']))\n",
    "    for name in top_ranks:\n",
    "        if top_ranks[name] == key:\n",
    "            key_name = name\n",
    "            break\n",
    "    #print(key, search_list[dt.date(2018,4,30)])\n",
    "    #print(key, search_list[key_min_date])\n",
    "    #print(key_min_date)\n",
    "    #print(type(key_min_date))\n",
    "    #print(values[key_min_date])\n",
    "    #print(values[key_min_date]['저가'])\n",
    "    k50_min[key]=values[key_min_date]['저가']\n",
    "    K50_min_date[key]=key_min_date\n",
    "    K50_gap[key]=values[-2]['종가'] - k50_min[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today_price = dict((key, value['종가']) for key, value in  k50_historical_prices.iloc[-1].items())\n",
    "Yesterday_price = dict((key, value['종가']) for key, value in  k50_historical_prices.iloc[-2].items())\n",
    "volume = dict()\n",
    "gap_percentage = dict()\n",
    "\n",
    "for index, content in enumerate(top_ranks):\n",
    "    volume[top_ranks[content]] = int(index + 1)\n",
    "    gap_percentage[top_ranks[content]] = float(\"%2.1f\"%(((Yesterday_price[top_ranks[content]]/k50_min[top_ranks[content]])-1)*100))\n",
    "\n",
    "tmp = {'Outstanding':k50_outstanding, \\\n",
    "      'Floating':k50_floating, \\\n",
    "      'Min_52_Date':K50_min_date, \\\n",
    "      'Min_52':k50_min, \\\n",
    "      'Yesterday_price':Yesterday_price,\\\n",
    "      'Today_price':Today_price,\\\n",
    "      'Gap':K50_gap,\\\n",
    "      'Gap_Percentage':gap_percentage,\\\n",
    "      'Volume':volume,\\\n",
    "      'Name':k50_name}\n",
    "k50_info = pd.DataFrame(tmp,columns=['Name', 'Min_52_Date', 'Min_52', 'Yesterday_price', 'Gap', 'Gap_Percentage', 'Today_price', 'Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "k50_info = k50_info.sort_values([\"Gap_Percentage\"], ascending=[True])\n",
    "display(k50_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
